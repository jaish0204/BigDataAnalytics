{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDbJWoO1yO8e"
   },
   "source": [
    "# Image Classification with CNN - LeNet5 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzQxqD6HyO8i"
   },
   "source": [
    "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFyVotRvyO8j"
   },
   "source": [
    "We will first download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTHLyL1fyO8j",
    "outputId": "d370c5a4-880a-4c54-d59c-0124eeeda1b2",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24280/3758875664.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO: Load the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# TODO: Load the dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# # # If your computer is slow, try to use a subset of data, e.g.\n",
    "# X_train = X_train[:10000]\n",
    "# y_train = y_train[:10000]\n",
    "# X_test = X_test[:2000]\n",
    "# y_test = y_test[:2000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8ShXIANyO8l"
   },
   "source": [
    "As you already know, this dataset contains 10 classes:\n",
    "* 0:\tT-shirt/top\n",
    "* 1:\tTrouser\n",
    "* 2:\tPullover\n",
    "* 3:\tDress\n",
    "* 4:\tCoat\n",
    "* 5:\tSandal\n",
    "* 6:\tShirt\n",
    "* 7:\tSneaker\n",
    "* 8:\tBag\n",
    "* 9:\tAnkle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BvNG0PbyO8l"
   },
   "source": [
    "You can have a look at some images if needed, even if you already know them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "lnjqgv-GyO8m",
    "outputId": "601a7abc-cfc7-4abd-999f-91455b94a089",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Explore the data, display some input images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "idx = np.random.randint(X_train.shape[0])\n",
    "\n",
    "plt.imshow(X_train[idx],cmap=\"gray_r\")\n",
    "plt.title(label_class[y_train[idx]])\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdYH6XW1yO8n"
   },
   "source": [
    "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjv8XMPByO8o",
    "outputId": "4749fe5e-c3ba-4618-9f58-206320bbb43e"
   },
   "outputs": [],
   "source": [
    "# TODO: Make the data preparation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train,num_classes=10)\n",
    "y_test_cat = to_categorical(y_test,num_classes=10)\n",
    "\n",
    "X_train_norm = X_train/225\n",
    "X_test_norm = X_test/225\n",
    "\n",
    "\n",
    "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
    "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train_norm.shape #Should be (60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9LKzxR9yO8o"
   },
   "source": [
    "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
    "\n",
    "The architecture is the following:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKyMFlL6yO8o",
    "outputId": "16a22cfa-7cd2-4ffb-c316-7e27084a292d"
   },
   "outputs": [],
   "source": [
    "# TODO: Build your model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def lenet5():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer C1\n",
    "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    # Layer S2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
    "    # Layer C3\n",
    "    model.add(Conv2D(filters=1, name='C3',kernel_size=(3,3),activation='relu'))\n",
    "    # Layer S4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
    "    # Before going into layer C5, we flatten our units\n",
    "    model.add(Flatten())\n",
    "    # Layer C5\n",
    "    model.add(Dense(120,activation='relu',name=\"C5\"))\n",
    "    # Layer F6\n",
    "    model.add(Dense(84,activation='relu',name=\"F5\"))\n",
    "    # Output layer\n",
    "    model.add(Dense(units=10, activation = 'softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "lenet5().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1qBEauqyO8p"
   },
   "source": [
    "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPL3aKnyyO8p",
    "outputId": "e9a04035-9181-4b4b-b3a1-8267fd8b9419",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Compile and fit your model\n",
    "import os\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model = lenet5()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define now our callbacks\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "\n",
    "# Finally fit the model\n",
    "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf-SqjjOyO8q"
   },
   "source": [
    "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2FTj7TSyO8q"
   },
   "source": [
    "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPjJoMQZyO8q",
    "outputId": "d6addcc1-ffd8-4dc7-a737-637af8598873"
   },
   "outputs": [],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 1024\n",
    "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "\n",
    "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
    "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vulsgHiyO8q"
   },
   "source": [
    "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
    "\n",
    "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
    "* `horizontal_flip=True`\n",
    "\n",
    "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
    "\n",
    "Begin by creating an object `ImageDataGenerator` with this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:58:37.442182Z",
     "start_time": "2020-08-19T11:58:37.438397Z"
    },
    "id": "pas-fMSIyO8q"
   },
   "outputs": [],
   "source": [
    "# TODO: Instantiate an ImageDataGenerator object\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7nCnu9syO8r"
   },
   "source": [
    "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zt6wXa3IyO8r",
    "outputId": "de294918-396e-4a4b-8b9e-8d110430b189",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: train your model\n",
    "batch_size = 1024\n",
    "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
    "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
    "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuzFke8pyO8r"
   },
   "source": [
    "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsTm86tuyO8r",
    "outputId": "e605232d-0e6a-4bbd-d892-c02e0cff4356"
   },
   "outputs": [],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size=1024\n",
    "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "\n",
    "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
    "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOzkdGf7yO8s"
   },
   "source": [
    "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LeNet5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
