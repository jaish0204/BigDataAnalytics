{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaish0204/DataAnalytics/blob/main/LeNet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "3dd2c599-5860-4da2-8436-4022d87df9b2",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "26435584/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "44ae9797-fe83-4d7c-e841-095dc8bd1487",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx],cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjv8XMPByO8o",
        "outputId": "329db8ee-9838-4ae9-dbe4-809dfa81fd78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train,num_classes=10)\n",
        "y_test_cat = to_categorical(y_test,num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/225\n",
        "X_test_norm = X_test/225\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKyMFlL6yO8o",
        "outputId": "26bd895c-9f22-4be9-dfc3-e37743380235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 1)         55        \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 1)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25)                0         \n",
            "                                                                 \n",
            " C5 (Dense)                  (None, 120)               3120      \n",
            "                                                                 \n",
            " F5 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,249\n",
            "Trainable params: 14,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=1, name='C3',kernel_size=(3,3),activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120,activation='relu',name=\"C5\"))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84,activation='relu',name=\"F5\"))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "452be1aa-3dc0-49ce-c06e-5dc0d36918a8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 12s 39ms/step - loss: 2.0935 - accuracy: 0.3156 - val_loss: 1.6987 - val_accuracy: 0.4804\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 1.2827 - accuracy: 0.5897 - val_loss: 0.9874 - val_accuracy: 0.6629\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.8746 - accuracy: 0.6858 - val_loss: 0.8031 - val_accuracy: 0.7027\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.7554 - accuracy: 0.7207 - val_loss: 0.7306 - val_accuracy: 0.7289\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.7000 - accuracy: 0.7421 - val_loss: 0.6931 - val_accuracy: 0.7478\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.6665 - accuracy: 0.7543 - val_loss: 0.6712 - val_accuracy: 0.7575\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.6427 - accuracy: 0.7637 - val_loss: 0.6533 - val_accuracy: 0.7606\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.6271 - accuracy: 0.7699 - val_loss: 0.6422 - val_accuracy: 0.7619\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.6144 - accuracy: 0.7757 - val_loss: 0.6178 - val_accuracy: 0.7745\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.5982 - accuracy: 0.7832 - val_loss: 0.6085 - val_accuracy: 0.7806\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5876 - accuracy: 0.7865 - val_loss: 0.5976 - val_accuracy: 0.7848\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5772 - accuracy: 0.7912 - val_loss: 0.5821 - val_accuracy: 0.7884\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5676 - accuracy: 0.7927 - val_loss: 0.5745 - val_accuracy: 0.7927\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.5559 - accuracy: 0.7987 - val_loss: 0.5692 - val_accuracy: 0.7954\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.5498 - accuracy: 0.8007 - val_loss: 0.5645 - val_accuracy: 0.7944\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5422 - accuracy: 0.8030 - val_loss: 0.5535 - val_accuracy: 0.7982\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5345 - accuracy: 0.8074 - val_loss: 0.5539 - val_accuracy: 0.7973\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.5291 - accuracy: 0.8080 - val_loss: 0.5444 - val_accuracy: 0.8036\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5216 - accuracy: 0.8124 - val_loss: 0.5419 - val_accuracy: 0.8033\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5177 - accuracy: 0.8128 - val_loss: 0.5283 - val_accuracy: 0.8090\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5108 - accuracy: 0.8162 - val_loss: 0.5256 - val_accuracy: 0.8120\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5067 - accuracy: 0.8169 - val_loss: 0.5232 - val_accuracy: 0.8113\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.5054 - accuracy: 0.8173 - val_loss: 0.5182 - val_accuracy: 0.8108\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4986 - accuracy: 0.8190 - val_loss: 0.5157 - val_accuracy: 0.8149\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4936 - accuracy: 0.8214 - val_loss: 0.5109 - val_accuracy: 0.8132\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4912 - accuracy: 0.8223 - val_loss: 0.5036 - val_accuracy: 0.8185\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4873 - accuracy: 0.8233 - val_loss: 0.5072 - val_accuracy: 0.8136\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4855 - accuracy: 0.8249 - val_loss: 0.5062 - val_accuracy: 0.8134\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4803 - accuracy: 0.8267 - val_loss: 0.4972 - val_accuracy: 0.8183\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4789 - accuracy: 0.8264 - val_loss: 0.4944 - val_accuracy: 0.8192\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4752 - accuracy: 0.8281 - val_loss: 0.4930 - val_accuracy: 0.8199\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4714 - accuracy: 0.8293 - val_loss: 0.4942 - val_accuracy: 0.8172\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4700 - accuracy: 0.8296 - val_loss: 0.4902 - val_accuracy: 0.8207\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4696 - accuracy: 0.8291 - val_loss: 0.4897 - val_accuracy: 0.8192\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4654 - accuracy: 0.8319 - val_loss: 0.4854 - val_accuracy: 0.8206\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4612 - accuracy: 0.8326 - val_loss: 0.4816 - val_accuracy: 0.8222\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4591 - accuracy: 0.8330 - val_loss: 0.4799 - val_accuracy: 0.8238\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4573 - accuracy: 0.8332 - val_loss: 0.4781 - val_accuracy: 0.8233\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4562 - accuracy: 0.8341 - val_loss: 0.4777 - val_accuracy: 0.8236\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4517 - accuracy: 0.8364 - val_loss: 0.4734 - val_accuracy: 0.8250\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4514 - accuracy: 0.8365 - val_loss: 0.4739 - val_accuracy: 0.8248\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4478 - accuracy: 0.8364 - val_loss: 0.4726 - val_accuracy: 0.8249\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4461 - accuracy: 0.8375 - val_loss: 0.4695 - val_accuracy: 0.8264\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4442 - accuracy: 0.8385 - val_loss: 0.4728 - val_accuracy: 0.8261\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4444 - accuracy: 0.8380 - val_loss: 0.4637 - val_accuracy: 0.8264\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4394 - accuracy: 0.8396 - val_loss: 0.4693 - val_accuracy: 0.8281\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4385 - accuracy: 0.8396 - val_loss: 0.4637 - val_accuracy: 0.8294\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4366 - accuracy: 0.8394 - val_loss: 0.4613 - val_accuracy: 0.8301\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4345 - accuracy: 0.8416 - val_loss: 0.4563 - val_accuracy: 0.8315\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4324 - accuracy: 0.8415 - val_loss: 0.4584 - val_accuracy: 0.8303\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4296 - accuracy: 0.8427 - val_loss: 0.4585 - val_accuracy: 0.8320\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4295 - accuracy: 0.8433 - val_loss: 0.4579 - val_accuracy: 0.8289\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4336 - accuracy: 0.8400 - val_loss: 0.4652 - val_accuracy: 0.8258\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4288 - accuracy: 0.8430 - val_loss: 0.4497 - val_accuracy: 0.8351\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4225 - accuracy: 0.8450 - val_loss: 0.4484 - val_accuracy: 0.8347\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4222 - accuracy: 0.8447 - val_loss: 0.4510 - val_accuracy: 0.8332\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4214 - accuracy: 0.8455 - val_loss: 0.4467 - val_accuracy: 0.8339\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4187 - accuracy: 0.8464 - val_loss: 0.4491 - val_accuracy: 0.8338\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4211 - accuracy: 0.8451 - val_loss: 0.4468 - val_accuracy: 0.8346\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4180 - accuracy: 0.8466 - val_loss: 0.4488 - val_accuracy: 0.8344\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4166 - accuracy: 0.8468 - val_loss: 0.4421 - val_accuracy: 0.8378\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4142 - accuracy: 0.8471 - val_loss: 0.4439 - val_accuracy: 0.8383\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4153 - accuracy: 0.8475 - val_loss: 0.4434 - val_accuracy: 0.8357\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4118 - accuracy: 0.8489 - val_loss: 0.4452 - val_accuracy: 0.8374\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4102 - accuracy: 0.8486 - val_loss: 0.4394 - val_accuracy: 0.8392\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4108 - accuracy: 0.8491 - val_loss: 0.4366 - val_accuracy: 0.8407\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4095 - accuracy: 0.8481 - val_loss: 0.4367 - val_accuracy: 0.8398\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4078 - accuracy: 0.8493 - val_loss: 0.4381 - val_accuracy: 0.8364\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4056 - accuracy: 0.8514 - val_loss: 0.4365 - val_accuracy: 0.8383\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4062 - accuracy: 0.8504 - val_loss: 0.4343 - val_accuracy: 0.8403\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4043 - accuracy: 0.8511 - val_loss: 0.4394 - val_accuracy: 0.8378\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4041 - accuracy: 0.8504 - val_loss: 0.4459 - val_accuracy: 0.8356\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4022 - accuracy: 0.8529 - val_loss: 0.4339 - val_accuracy: 0.8396\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4014 - accuracy: 0.8527 - val_loss: 0.4316 - val_accuracy: 0.8412\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3999 - accuracy: 0.8532 - val_loss: 0.4438 - val_accuracy: 0.8373\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4000 - accuracy: 0.8532 - val_loss: 0.4335 - val_accuracy: 0.8395\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4015 - accuracy: 0.8525 - val_loss: 0.4322 - val_accuracy: 0.8428\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3977 - accuracy: 0.8537 - val_loss: 0.4367 - val_accuracy: 0.8391\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3982 - accuracy: 0.8531 - val_loss: 0.4334 - val_accuracy: 0.8388\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3950 - accuracy: 0.8547 - val_loss: 0.4294 - val_accuracy: 0.8422\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.3968 - accuracy: 0.8534 - val_loss: 0.4286 - val_accuracy: 0.8431\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3945 - accuracy: 0.8547 - val_loss: 0.4317 - val_accuracy: 0.8422\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3940 - accuracy: 0.8540 - val_loss: 0.4261 - val_accuracy: 0.8409\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3923 - accuracy: 0.8554 - val_loss: 0.4312 - val_accuracy: 0.8413\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3913 - accuracy: 0.8566 - val_loss: 0.4287 - val_accuracy: 0.8412\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3903 - accuracy: 0.8555 - val_loss: 0.4258 - val_accuracy: 0.8445\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3895 - accuracy: 0.8557 - val_loss: 0.4305 - val_accuracy: 0.8409\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3899 - accuracy: 0.8552 - val_loss: 0.4280 - val_accuracy: 0.8408\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3892 - accuracy: 0.8556 - val_loss: 0.4222 - val_accuracy: 0.8452\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3889 - accuracy: 0.8558 - val_loss: 0.4199 - val_accuracy: 0.8439\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3859 - accuracy: 0.8571 - val_loss: 0.4318 - val_accuracy: 0.8392\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3846 - accuracy: 0.8584 - val_loss: 0.4224 - val_accuracy: 0.8438\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3849 - accuracy: 0.8577 - val_loss: 0.4186 - val_accuracy: 0.8444\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3832 - accuracy: 0.8583 - val_loss: 0.4194 - val_accuracy: 0.8459\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3833 - accuracy: 0.8581 - val_loss: 0.4166 - val_accuracy: 0.8475\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3818 - accuracy: 0.8590 - val_loss: 0.4179 - val_accuracy: 0.8447\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3829 - accuracy: 0.8585 - val_loss: 0.4224 - val_accuracy: 0.8425\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3807 - accuracy: 0.8590 - val_loss: 0.4309 - val_accuracy: 0.8409\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3820 - accuracy: 0.8594 - val_loss: 0.4227 - val_accuracy: 0.8435\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3786 - accuracy: 0.8607 - val_loss: 0.4183 - val_accuracy: 0.8481\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6cbf6d910>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "30a74b7d-2cac-4323-8e4d-4b1e39874e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with CNN: 0.8603666666666666\n",
            "accuracy on test with CNN: 0.8481\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "d244fb09-62dd-4058-d903-fa549c8f97cf",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 4s 55ms/step - loss: 0.6443 - accuracy: 0.7895 - val_loss: 0.4556 - val_accuracy: 0.8343\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.4579 - accuracy: 0.8328 - val_loss: 0.4455 - val_accuracy: 0.8372\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4398 - accuracy: 0.8385 - val_loss: 0.4410 - val_accuracy: 0.8383\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.4335 - accuracy: 0.8399 - val_loss: 0.4372 - val_accuracy: 0.8380\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 4s 67ms/step - loss: 0.4260 - accuracy: 0.8417 - val_loss: 0.4361 - val_accuracy: 0.8376\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.4285 - accuracy: 0.8410 - val_loss: 0.4340 - val_accuracy: 0.8394\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.4231 - accuracy: 0.8423 - val_loss: 0.4286 - val_accuracy: 0.8399\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4207 - accuracy: 0.8449 - val_loss: 0.4320 - val_accuracy: 0.8396\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4214 - accuracy: 0.8446 - val_loss: 0.4305 - val_accuracy: 0.8422\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 3s 51ms/step - loss: 0.4183 - accuracy: 0.8455 - val_loss: 0.4346 - val_accuracy: 0.8381\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.4127 - accuracy: 0.8467 - val_loss: 0.4276 - val_accuracy: 0.8427\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4148 - accuracy: 0.8479 - val_loss: 0.4257 - val_accuracy: 0.8454\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.4097 - accuracy: 0.8485 - val_loss: 0.4275 - val_accuracy: 0.8399\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.4096 - accuracy: 0.8479 - val_loss: 0.4207 - val_accuracy: 0.8455\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.4077 - accuracy: 0.8495 - val_loss: 0.4229 - val_accuracy: 0.8435\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4059 - accuracy: 0.8501 - val_loss: 0.4259 - val_accuracy: 0.8396\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.4055 - accuracy: 0.8490 - val_loss: 0.4186 - val_accuracy: 0.8463\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.4022 - accuracy: 0.8517 - val_loss: 0.4257 - val_accuracy: 0.8436\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.4001 - accuracy: 0.8530 - val_loss: 0.4229 - val_accuracy: 0.8444\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 4s 60ms/step - loss: 0.4002 - accuracy: 0.8510 - val_loss: 0.4220 - val_accuracy: 0.8416\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.4002 - accuracy: 0.8516 - val_loss: 0.4192 - val_accuracy: 0.8453\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3979 - accuracy: 0.8526 - val_loss: 0.4236 - val_accuracy: 0.8413\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3972 - accuracy: 0.8524 - val_loss: 0.4241 - val_accuracy: 0.8435\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3985 - accuracy: 0.8529 - val_loss: 0.4186 - val_accuracy: 0.8458\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.3935 - accuracy: 0.8534 - val_loss: 0.4202 - val_accuracy: 0.8460\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.3943 - accuracy: 0.8536 - val_loss: 0.4169 - val_accuracy: 0.8454\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3919 - accuracy: 0.8546 - val_loss: 0.4149 - val_accuracy: 0.8484\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3948 - accuracy: 0.8534 - val_loss: 0.4179 - val_accuracy: 0.8468\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3899 - accuracy: 0.8555 - val_loss: 0.4193 - val_accuracy: 0.8432\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3869 - accuracy: 0.8566 - val_loss: 0.4227 - val_accuracy: 0.8410\n",
            "Epoch 31/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.3910 - accuracy: 0.8555 - val_loss: 0.4238 - val_accuracy: 0.8424\n",
            "Epoch 32/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3899 - accuracy: 0.8557 - val_loss: 0.4149 - val_accuracy: 0.8494\n",
            "Epoch 33/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3883 - accuracy: 0.8556 - val_loss: 0.4152 - val_accuracy: 0.8451\n",
            "Epoch 34/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3867 - accuracy: 0.8584 - val_loss: 0.4149 - val_accuracy: 0.8465\n",
            "Epoch 35/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3874 - accuracy: 0.8569 - val_loss: 0.4168 - val_accuracy: 0.8447\n",
            "Epoch 36/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3836 - accuracy: 0.8579 - val_loss: 0.4182 - val_accuracy: 0.8454\n",
            "Epoch 37/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3839 - accuracy: 0.8570 - val_loss: 0.4118 - val_accuracy: 0.8496\n",
            "Epoch 38/100\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.3825 - accuracy: 0.8590 - val_loss: 0.4150 - val_accuracy: 0.8479\n",
            "Epoch 39/100\n",
            "58/58 [==============================] - 4s 60ms/step - loss: 0.3814 - accuracy: 0.8595 - val_loss: 0.4140 - val_accuracy: 0.8467\n",
            "Epoch 40/100\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.3807 - accuracy: 0.8586 - val_loss: 0.4103 - val_accuracy: 0.8468\n",
            "Epoch 41/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3814 - accuracy: 0.8580 - val_loss: 0.4124 - val_accuracy: 0.8459\n",
            "Epoch 42/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3796 - accuracy: 0.8599 - val_loss: 0.4124 - val_accuracy: 0.8471\n",
            "Epoch 43/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3806 - accuracy: 0.8587 - val_loss: 0.4183 - val_accuracy: 0.8472\n",
            "Epoch 44/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.3811 - accuracy: 0.8592 - val_loss: 0.4169 - val_accuracy: 0.8483\n",
            "Epoch 45/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3794 - accuracy: 0.8593 - val_loss: 0.4130 - val_accuracy: 0.8473\n",
            "Epoch 46/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3777 - accuracy: 0.8601 - val_loss: 0.4122 - val_accuracy: 0.8498\n",
            "Epoch 47/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3759 - accuracy: 0.8608 - val_loss: 0.4144 - val_accuracy: 0.8498\n",
            "Epoch 48/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3790 - accuracy: 0.8577 - val_loss: 0.4081 - val_accuracy: 0.8490\n",
            "Epoch 49/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3758 - accuracy: 0.8607 - val_loss: 0.4163 - val_accuracy: 0.8472\n",
            "Epoch 50/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.3740 - accuracy: 0.8615 - val_loss: 0.4128 - val_accuracy: 0.8504\n",
            "Epoch 51/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3799 - accuracy: 0.8598 - val_loss: 0.4069 - val_accuracy: 0.8509\n",
            "Epoch 52/100\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.3730 - accuracy: 0.8619 - val_loss: 0.4047 - val_accuracy: 0.8534\n",
            "Epoch 53/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3722 - accuracy: 0.8619 - val_loss: 0.4115 - val_accuracy: 0.8492\n",
            "Epoch 54/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.3728 - accuracy: 0.8613 - val_loss: 0.4044 - val_accuracy: 0.8523\n",
            "Epoch 55/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3738 - accuracy: 0.8607 - val_loss: 0.4097 - val_accuracy: 0.8504\n",
            "Epoch 56/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.3746 - accuracy: 0.8611 - val_loss: 0.4130 - val_accuracy: 0.8487\n",
            "Epoch 57/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3704 - accuracy: 0.8617 - val_loss: 0.4073 - val_accuracy: 0.8519\n",
            "Epoch 58/100\n",
            "58/58 [==============================] - 4s 60ms/step - loss: 0.3659 - accuracy: 0.8650 - val_loss: 0.4091 - val_accuracy: 0.8484\n",
            "Epoch 59/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.3707 - accuracy: 0.8625 - val_loss: 0.4257 - val_accuracy: 0.8433\n",
            "Epoch 60/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3680 - accuracy: 0.8638 - val_loss: 0.4089 - val_accuracy: 0.8507\n",
            "Epoch 61/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3696 - accuracy: 0.8629 - val_loss: 0.4052 - val_accuracy: 0.8516\n",
            "Epoch 62/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3680 - accuracy: 0.8637 - val_loss: 0.4012 - val_accuracy: 0.8537\n",
            "Epoch 63/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3650 - accuracy: 0.8633 - val_loss: 0.4052 - val_accuracy: 0.8538\n",
            "Epoch 64/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3662 - accuracy: 0.8641 - val_loss: 0.4066 - val_accuracy: 0.8496\n",
            "Epoch 65/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3643 - accuracy: 0.8645 - val_loss: 0.4045 - val_accuracy: 0.8518\n",
            "Epoch 66/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3647 - accuracy: 0.8626 - val_loss: 0.4054 - val_accuracy: 0.8509\n",
            "Epoch 67/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3647 - accuracy: 0.8645 - val_loss: 0.4017 - val_accuracy: 0.8534\n",
            "Epoch 68/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3653 - accuracy: 0.8637 - val_loss: 0.4070 - val_accuracy: 0.8507\n",
            "Epoch 69/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3642 - accuracy: 0.8636 - val_loss: 0.4114 - val_accuracy: 0.8468\n",
            "Epoch 70/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3650 - accuracy: 0.8640 - val_loss: 0.4008 - val_accuracy: 0.8546\n",
            "Epoch 71/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3630 - accuracy: 0.8644 - val_loss: 0.4114 - val_accuracy: 0.8503\n",
            "Epoch 72/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3609 - accuracy: 0.8656 - val_loss: 0.4022 - val_accuracy: 0.8507\n",
            "Epoch 73/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3648 - accuracy: 0.8652 - val_loss: 0.4075 - val_accuracy: 0.8502\n",
            "Epoch 74/100\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.3626 - accuracy: 0.8649 - val_loss: 0.4008 - val_accuracy: 0.8512\n",
            "Epoch 75/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3636 - accuracy: 0.8630 - val_loss: 0.4047 - val_accuracy: 0.8512\n",
            "Epoch 76/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3611 - accuracy: 0.8656 - val_loss: 0.4052 - val_accuracy: 0.8538\n",
            "Epoch 77/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3597 - accuracy: 0.8655 - val_loss: 0.4006 - val_accuracy: 0.8553\n",
            "Epoch 78/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.3613 - accuracy: 0.8659 - val_loss: 0.4045 - val_accuracy: 0.8506\n",
            "Epoch 79/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3580 - accuracy: 0.8669 - val_loss: 0.4074 - val_accuracy: 0.8532\n",
            "Epoch 80/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3585 - accuracy: 0.8666 - val_loss: 0.4005 - val_accuracy: 0.8534\n",
            "Epoch 81/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3598 - accuracy: 0.8652 - val_loss: 0.3974 - val_accuracy: 0.8539\n",
            "Epoch 82/100\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.3558 - accuracy: 0.8684 - val_loss: 0.4016 - val_accuracy: 0.8540\n",
            "Epoch 83/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.3573 - accuracy: 0.8654 - val_loss: 0.4054 - val_accuracy: 0.8488\n",
            "Epoch 84/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3591 - accuracy: 0.8670 - val_loss: 0.4007 - val_accuracy: 0.8525\n",
            "Epoch 85/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3576 - accuracy: 0.8665 - val_loss: 0.4014 - val_accuracy: 0.8523\n",
            "Epoch 86/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.3553 - accuracy: 0.8673 - val_loss: 0.4010 - val_accuracy: 0.8526\n",
            "Epoch 87/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3580 - accuracy: 0.8662 - val_loss: 0.4078 - val_accuracy: 0.8488\n",
            "Epoch 88/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.3552 - accuracy: 0.8667 - val_loss: 0.4028 - val_accuracy: 0.8532\n",
            "Epoch 89/100\n",
            "58/58 [==============================] - 3s 51ms/step - loss: 0.3544 - accuracy: 0.8680 - val_loss: 0.4017 - val_accuracy: 0.8530\n",
            "Epoch 90/100\n",
            "58/58 [==============================] - 3s 51ms/step - loss: 0.3536 - accuracy: 0.8682 - val_loss: 0.3984 - val_accuracy: 0.8550\n",
            "Epoch 91/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.3549 - accuracy: 0.8664 - val_loss: 0.3961 - val_accuracy: 0.8562\n",
            "Epoch 92/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.3560 - accuracy: 0.8674 - val_loss: 0.4032 - val_accuracy: 0.8514\n",
            "Epoch 93/100\n",
            "44/58 [=====================>........] - ETA: 0s - loss: 0.3556 - accuracy: 0.8659"
          ]
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsTm86tuyO8r"
      },
      "outputs": [],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LeNet5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}